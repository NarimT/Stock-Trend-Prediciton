{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc805603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running batch1_finance with: ['NVIDIA', 'NVIDIA stock', 'NVDA stock', 'AI', 'GPU']\n",
      "Saved batch1_finance_trends.csv (79 rows, columns: ['NVIDIA', 'NVIDIA stock', 'NVDA stock', 'AI', 'GPU'])\n",
      "\n",
      "Running batch2_company with: ['NVIDIA', 'AMD', 'Intel', 'TSMC', 'OpenAI']\n",
      "Saved batch2_company_trends.csv (79 rows, columns: ['NVIDIA', 'AMD', 'Intel', 'TSMC', 'OpenAI'])\n",
      "\n",
      "Anchor scales: {'batch1_finance': np.int64(24), 'batch2_company': np.int64(100)}\n",
      "Normalized batch1_finance (scale factor = 1.000)\n",
      "Normalized batch2_company (scale factor = 0.240)\n",
      "\n",
      "Merged dataset saved as: data/google_trends/all_batches_merged_normalized.csv\n",
      "            NVIDIA  NVIDIA stock  NVDA stock     AI  GPU   AMD  Intel  TSMC  \\\n",
      "date                                                                          \n",
      "2025-06-01     7.0           2.0         1.0   89.0  3.0  6.24   5.04  0.24   \n",
      "2025-06-08     7.0           1.0         1.0   93.0  3.0  6.24   4.80  0.24   \n",
      "2025-06-15     6.0           1.0         1.0   91.0  3.0  6.48   4.80  0.24   \n",
      "2025-06-22     7.0           2.0         1.0   89.0  3.0  6.72   5.04  0.24   \n",
      "2025-06-29     6.0           1.0         1.0  100.0  3.0  6.24   5.04  0.24   \n",
      "\n",
      "            OpenAI  \n",
      "date                \n",
      "2025-06-01    2.64  \n",
      "2025-06-08    3.36  \n",
      "2025-06-15    2.88  \n",
      "2025-06-22    2.64  \n",
      "2025-06-29    2.88  \n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize connection\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=0)\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(\"data/google_trends\", exist_ok=True)\n",
    "\n",
    "# Define batches (max 5 keywords each)\n",
    "batches = {\n",
    "    \"batch1_finance\": [\"NVIDIA\", \"NVIDIA stock\", \"NVDA stock\", \"AI\", \"GPU\"],\n",
    "    \"batch2_company\": [\"NVIDIA\", \"AMD\", \"Intel\", \"TSMC\", \"OpenAI\"],\n",
    "}\n",
    "\n",
    "timeframe = \"2024-01-01 2025-06-30\"\n",
    "geo = \"\"  # Global\n",
    "gprop = \"\"  # Web search\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "# Step 1: Run all batches\n",
    "for name, kw_list in batches.items():\n",
    "    print(f\"\\nRunning {name} with: {kw_list}\")\n",
    "    pytrends.build_payload(kw_list=kw_list, timeframe=timeframe, geo=geo, gprop=gprop)\n",
    "    df = pytrends.interest_over_time()\n",
    "\n",
    "    # Remove incomplete final row if present\n",
    "    if \"isPartial\" in df.columns:\n",
    "        df = df.drop(columns=[\"isPartial\"])\n",
    "\n",
    "    all_data[name] = df\n",
    "    df.to_csv(f\"data/google_trends/{name}_trends.csv\")\n",
    "\n",
    "    print(f\"Saved {name}_trends.csv ({len(df)} rows, columns: {list(df.columns)})\")\n",
    "    time.sleep(2)  # Rate limit protection\n",
    "\n",
    "# Step 2: Normalize across batches using NVIDIA as the anchor\n",
    "anchor = \"NVIDIA\"\n",
    "\n",
    "# Find the peak value of NVIDIA in each batch\n",
    "scales = {name: df[anchor].max() for name, df in all_data.items()}\n",
    "print(\"\\nAnchor scales:\", scales)\n",
    "\n",
    "# Use the first batch as baseline\n",
    "base_batch = list(scales.keys())[0]\n",
    "base_scale = scales[base_batch]\n",
    "\n",
    "# Normalize all batches so NVIDIA aligns\n",
    "normalized_data = {}\n",
    "for name, df in all_data.items():\n",
    "    factor = base_scale / scales[name]\n",
    "    df_scaled = df * factor\n",
    "    normalized_data[name] = df_scaled\n",
    "    print(f\"Normalized {name} (scale factor = {factor:.3f})\")\n",
    "\n",
    "# Step 3: Merge normalized batches on date\n",
    "merged = pd.concat(normalized_data.values(), axis=1)\n",
    "merged = merged.loc[:, ~merged.columns.duplicated()]  # remove duplicate columns\n",
    "merged.to_csv(\"data/google_trends/all_batches_merged_normalized.csv\")\n",
    "\n",
    "print(\"\\nMerged dataset saved as: data/google_trends/all_batches_merged_normalized.csv\")\n",
    "print(merged.tail())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "at82-03-stock-trend-predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
