{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35564751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch_summary import summary\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import numpy as np\n",
    "import talib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9801eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data, window_size=36, normalize=True):\n",
    "\n",
    "        X_data = np.array(X_data, dtype=np.float32)\n",
    "        y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "        # --- Create sliding windows ---\n",
    "        windows = []\n",
    "        for i in range(len(X_data) - window_size + 1):\n",
    "            window = X_data[i:i + window_size]  # flatten features\n",
    "            windows.append(window)\n",
    "        self.X_data = np.array(windows, dtype=np.float32)\n",
    "\n",
    "        # Align y_data: pick the last value of each window as target\n",
    "        self.y_data = y_data[window_size - 1:]\n",
    "\n",
    "\n",
    "        self.length = len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.X_data[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y_data[index], dtype=torch.float32)\n",
    "        return x.T, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6727c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGSRModel(nn.Module):\n",
    "    def __init__(self, n_features=5, lstm_units=50, cnn1_filters=64, cnn2_filters=32):\n",
    "        \"\"\"\n",
    "        Initializes the PyTorch model based on the diagram.\n",
    "        \n",
    "        :param n_features: The number of features at each time step (input channels).\n",
    "        :param lstm_units: The number of hidden units in each LSTM layer.\n",
    "        :param cnn1_filters: The number of filters for the 1st CNN branch.\n",
    "        :param cnn2_filters: The number of filters for the 2nd CNN branch.\n",
    "        \"\"\"\n",
    "        super(HybridGSRModel, self).__init__()\n",
    "        \n",
    "        # --- Branch 1: 1st Convolution Neural Network ---\n",
    "        # Keras 'padding=same' with kernel=3 is padding=1\n",
    "        self.cnn_branch1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels=cnn1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2), # P1\n",
    "            \n",
    "            nn.Conv1d(in_channels=cnn1_filters, out_channels=cnn1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2), # P2\n",
    "            \n",
    "            nn.Conv1d(in_channels=cnn1_filters, out_channels=cnn1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2), # P3\n",
    "            \n",
    "            nn.Conv1d(in_channels=cnn1_filters, out_channels=cnn1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "            # F1 output\n",
    "        )\n",
    "        \n",
    "        # --- Branch 1: LSTM Network ---\n",
    "        # The input size for the LSTM is the number of filters from the CNN (cnn1_filters)\n",
    "        self.lstm_branch1 = nn.LSTM(\n",
    "            input_size=cnn1_filters, \n",
    "            hidden_size=lstm_units, \n",
    "            num_layers=3,         # 3 stacked LSTMs\n",
    "            batch_first=True      # Input shape is (batch, seq_len, features)\n",
    "        )\n",
    "        \n",
    "        # --- Branch 2: 2nd Convolution Neural Network ---\n",
    "        # Keras 'padding=same' with kernel=5 is padding=2\n",
    "        self.cnn_branch2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels=cnn2_filters, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv1d(in_channels=cnn2_filters, out_channels=cnn2_filters, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "            # 2nd CNN Output (before pooling)\n",
    "        )\n",
    "        \n",
    "        # --- Merging and Final Prediction Head ---\n",
    "        # The input to the dense layer is the concatenated output of:\n",
    "        # 1. Branch 1 LSTM (size: lstm_units)\n",
    "        # 2. Branch 2 CNN (size: cnn2_filters)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lstm_units + cnn2_filters, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1), # Final GSR Prediction (regression)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        :param x: Input tensor of shape (batch_size, timesteps, n_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        # PyTorch Conv1D expects (batch, channels, timesteps)\n",
    "        # Input 'x' is (batch, timesteps, channels), so we permute\n",
    "        x_cnn_input = x.permute(0, 2, 1)\n",
    "        \n",
    "        # --- Branch 1: CNN -> LSTM ---\n",
    "        \n",
    "        # 1. Pass through 1st CNN branch\n",
    "        f1_output = self.cnn_branch1(x_cnn_input) # Shape: (batch, cnn1_filters, reduced_timesteps)\n",
    "        \n",
    "        # 2. Prepare for LSTM\n",
    "        # LSTM (batch_first=True) expects (batch, timesteps, features/channels)\n",
    "        lstm_input = f1_output.permute(0, 2, 1) \n",
    "        \n",
    "        # 3. Pass through LSTM\n",
    "        # We only need the final hidden state of the last layer\n",
    "        # h_n shape is (num_layers, batch, hidden_size)\n",
    "        _, (h_n, c_n) = self.lstm_branch1(lstm_input)\n",
    "        \n",
    "        # Get the hidden state of the last layer\n",
    "        lstm_output = h_n[-1] # Shape: (batch, lstm_units)\n",
    "        \n",
    "        # --- Branch 2: CNN -> Global Pooling ---\n",
    "        \n",
    "        # 1. Pass through 2nd CNN branch\n",
    "        cnn2_output = self.cnn_branch2(x_cnn_input) # Shape: (batch, cnn2_filters, reduced_timesteps)\n",
    "        \n",
    "        # 2. Apply Global Average Pooling\n",
    "        # We average over the time dimension (dim=2)\n",
    "        cnn_pooled_output = torch.mean(cnn2_output, dim=2) # Shape: (batch, cnn2_filters)\n",
    "        \n",
    "        # --- Merging and Final Prediction ---\n",
    "        \n",
    "        # 1. Concatenate the outputs from both branches\n",
    "        merged = torch.cat((lstm_output, cnn_pooled_output), dim=1) # Shape: (batch, lstm_units + cnn2_filters)\n",
    "        \n",
    "        # 2. Pass through the final prediction head\n",
    "        prediction = self.head(merged)\n",
    "        \n",
    "        return prediction # Squeeze to (batch_size) for loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822e5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_features, ws, num_classes=1):\n",
    "        super(CNN_LSTM_Model, self).__init__()\n",
    "        conv_filters = 256\n",
    "        conv_kernel_size = 3\n",
    "        lstm_units = 256\n",
    "        \n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_features, out_channels=conv_filters, \n",
    "                      kernel_size=conv_kernel_size, padding='same'),\n",
    "            nn.BatchNorm1d(num_features=conv_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=conv_filters, out_channels=conv_filters, \n",
    "                      kernel_size=conv_kernel_size, padding='same'),\n",
    "            nn.BatchNorm1d(num_features=conv_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,1,1),\n",
    "            \n",
    "            nn.Conv1d(in_channels=conv_filters, out_channels=conv_filters, \n",
    "                      kernel_size=conv_kernel_size, padding='same'),\n",
    "            nn.BatchNorm1d(num_features=conv_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=conv_filters, out_channels=conv_filters, \n",
    "                      kernel_size=conv_kernel_size, padding='same'),\n",
    "            nn.BatchNorm1d(num_features=conv_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,1,1),\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            conv_filters, \n",
    "            lstm_units,\n",
    "            batch_first=True,\n",
    "            num_layers=2,\n",
    "            dropout=0.5  # This dropout is good!\n",
    "        )\n",
    "        \n",
    "        # --- NEW, SIMPLIFIED FULLY-CONNECTED LAYER ---\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # Add a dropout layer for regularization\n",
    "            # The input is now just 'lstm_units', NOT 'lstm_units * ws'\n",
    "            nn.Linear(in_features=lstm_units, out_features=num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_extractor(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "        # print(x.shape)\n",
    "        # out shape is (batch_size, seq_len, lstm_units)\n",
    "        out, _ = self.lstm(x)\n",
    "        \n",
    "        # --- KEY CHANGE ---\n",
    "        # We only take the output from the VERY LAST time step\n",
    "        # This is out[:, -1, :]\n",
    "        out = out[:, -1, :]\n",
    "        # print(out.shpe)\n",
    "        # No nn.Flatten() needed\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefb82d6-1cd0-40a5-a943-5a5c4098b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/ALL.csv')\n",
    "df.index = pd.to_datetime(df[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae86583-2c9a-4a50-925e-a93bd2f00bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>nvda_open</th>\n",
       "      <th>nvda_high</th>\n",
       "      <th>nvda_low</th>\n",
       "      <th>nvda_close</th>\n",
       "      <th>nvda_volume</th>\n",
       "      <th>amd_open</th>\n",
       "      <th>amd_high</th>\n",
       "      <th>amd_low</th>\n",
       "      <th>amd_close</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>gold_open</th>\n",
       "      <th>gold_high</th>\n",
       "      <th>gold_low</th>\n",
       "      <th>gold_close</th>\n",
       "      <th>gold_volume</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>nvda_sentiment_score</th>\n",
       "      <th>nvda_relevance_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:00:00+00:00</th>\n",
       "      <td>2020-01-02 09:00:00+00:00</td>\n",
       "      <td>5.9180</td>\n",
       "      <td>5.9481</td>\n",
       "      <td>5.9180</td>\n",
       "      <td>5.9389</td>\n",
       "      <td>60000</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.78000</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.63</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:00:00+00:00</th>\n",
       "      <td>2020-01-02 10:00:00+00:00</td>\n",
       "      <td>5.9389</td>\n",
       "      <td>5.9486</td>\n",
       "      <td>5.9372</td>\n",
       "      <td>5.9449</td>\n",
       "      <td>29920</td>\n",
       "      <td>46.64</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 11:00:00+00:00</th>\n",
       "      <td>2020-01-02 11:00:00+00:00</td>\n",
       "      <td>5.9486</td>\n",
       "      <td>5.9501</td>\n",
       "      <td>5.9436</td>\n",
       "      <td>5.9436</td>\n",
       "      <td>37800</td>\n",
       "      <td>46.85</td>\n",
       "      <td>46.92000</td>\n",
       "      <td>46.71</td>\n",
       "      <td>46.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 12:00:00+00:00</th>\n",
       "      <td>2020-01-02 12:00:00+00:00</td>\n",
       "      <td>5.9329</td>\n",
       "      <td>5.9481</td>\n",
       "      <td>5.9242</td>\n",
       "      <td>5.9464</td>\n",
       "      <td>614480</td>\n",
       "      <td>46.76</td>\n",
       "      <td>46.88000</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.86</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 13:00:00+00:00</th>\n",
       "      <td>2020-01-02 13:00:00+00:00</td>\n",
       "      <td>5.9456</td>\n",
       "      <td>5.9625</td>\n",
       "      <td>5.9247</td>\n",
       "      <td>5.9556</td>\n",
       "      <td>1660520</td>\n",
       "      <td>46.86</td>\n",
       "      <td>46.95000</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 19:00:00+00:00</th>\n",
       "      <td>2025-06-30 19:00:00+00:00</td>\n",
       "      <td>157.7411</td>\n",
       "      <td>158.6510</td>\n",
       "      <td>157.6611</td>\n",
       "      <td>157.8611</td>\n",
       "      <td>26770205</td>\n",
       "      <td>141.72</td>\n",
       "      <td>142.24000</td>\n",
       "      <td>141.22</td>\n",
       "      <td>141.89</td>\n",
       "      <td>...</td>\n",
       "      <td>107760.75</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>3298.40</td>\n",
       "      <td>3309.47</td>\n",
       "      <td>3297.98</td>\n",
       "      <td>3308.65</td>\n",
       "      <td>10356.0</td>\n",
       "      <td>0.211782</td>\n",
       "      <td>0.053219</td>\n",
       "      <td>0.150592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 20:00:00+00:00</th>\n",
       "      <td>2025-06-30 20:00:00+00:00</td>\n",
       "      <td>157.8611</td>\n",
       "      <td>158.6600</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>72869000</td>\n",
       "      <td>141.89</td>\n",
       "      <td>144.01955</td>\n",
       "      <td>141.01</td>\n",
       "      <td>141.70</td>\n",
       "      <td>...</td>\n",
       "      <td>107528.57</td>\n",
       "      <td>9128.0</td>\n",
       "      <td>3308.65</td>\n",
       "      <td>3309.13</td>\n",
       "      <td>3302.22</td>\n",
       "      <td>3302.95</td>\n",
       "      <td>4943.0</td>\n",
       "      <td>0.358923</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.043264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 21:00:00+00:00</th>\n",
       "      <td>2025-06-30 21:00:00+00:00</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>158.6600</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>223935</td>\n",
       "      <td>141.65</td>\n",
       "      <td>143.77955</td>\n",
       "      <td>141.01</td>\n",
       "      <td>141.52</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190412</td>\n",
       "      <td>0.122056</td>\n",
       "      <td>0.208046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 22:00:00+00:00</th>\n",
       "      <td>2025-06-30 22:00:00+00:00</td>\n",
       "      <td>157.7611</td>\n",
       "      <td>157.7911</td>\n",
       "      <td>157.4911</td>\n",
       "      <td>157.5113</td>\n",
       "      <td>219009</td>\n",
       "      <td>141.52</td>\n",
       "      <td>141.75000</td>\n",
       "      <td>141.33</td>\n",
       "      <td>141.44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 23:00:00+00:00</th>\n",
       "      <td>2025-06-30 23:00:00+00:00</td>\n",
       "      <td>157.5209</td>\n",
       "      <td>157.6111</td>\n",
       "      <td>157.4811</td>\n",
       "      <td>157.5211</td>\n",
       "      <td>211019</td>\n",
       "      <td>141.40</td>\n",
       "      <td>141.46000</td>\n",
       "      <td>141.22</td>\n",
       "      <td>141.39</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171347</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.159569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21925 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           timestamp  nvda_open  nvda_high  \\\n",
       "timestamp                                                                    \n",
       "2020-01-02 09:00:00+00:00  2020-01-02 09:00:00+00:00     5.9180     5.9481   \n",
       "2020-01-02 10:00:00+00:00  2020-01-02 10:00:00+00:00     5.9389     5.9486   \n",
       "2020-01-02 11:00:00+00:00  2020-01-02 11:00:00+00:00     5.9486     5.9501   \n",
       "2020-01-02 12:00:00+00:00  2020-01-02 12:00:00+00:00     5.9329     5.9481   \n",
       "2020-01-02 13:00:00+00:00  2020-01-02 13:00:00+00:00     5.9456     5.9625   \n",
       "...                                              ...        ...        ...   \n",
       "2025-06-30 19:00:00+00:00  2025-06-30 19:00:00+00:00   157.7411   158.6510   \n",
       "2025-06-30 20:00:00+00:00  2025-06-30 20:00:00+00:00   157.8611   158.6600   \n",
       "2025-06-30 21:00:00+00:00  2025-06-30 21:00:00+00:00   157.7811   158.6600   \n",
       "2025-06-30 22:00:00+00:00  2025-06-30 22:00:00+00:00   157.7611   157.7911   \n",
       "2025-06-30 23:00:00+00:00  2025-06-30 23:00:00+00:00   157.5209   157.6111   \n",
       "\n",
       "                           nvda_low  nvda_close  nvda_volume  amd_open  \\\n",
       "timestamp                                                                \n",
       "2020-01-02 09:00:00+00:00    5.9180      5.9389        60000     46.63   \n",
       "2020-01-02 10:00:00+00:00    5.9372      5.9449        29920     46.64   \n",
       "2020-01-02 11:00:00+00:00    5.9436      5.9436        37800     46.85   \n",
       "2020-01-02 12:00:00+00:00    5.9242      5.9464       614480     46.76   \n",
       "2020-01-02 13:00:00+00:00    5.9247      5.9556      1660520     46.86   \n",
       "...                             ...         ...          ...       ...   \n",
       "2025-06-30 19:00:00+00:00  157.6611    157.8611     26770205    141.72   \n",
       "2025-06-30 20:00:00+00:00  155.9600    157.7811     72869000    141.89   \n",
       "2025-06-30 21:00:00+00:00  155.9600    157.7811       223935    141.65   \n",
       "2025-06-30 22:00:00+00:00  157.4911    157.5113       219009    141.52   \n",
       "2025-06-30 23:00:00+00:00  157.4811    157.5211       211019    141.40   \n",
       "\n",
       "                            amd_high  amd_low  amd_close  ...  btc_close  \\\n",
       "timestamp                                                 ...              \n",
       "2020-01-02 09:00:00+00:00   46.78000    46.63      46.63  ...        NaN   \n",
       "2020-01-02 10:00:00+00:00   47.00000    46.63      46.80  ...        NaN   \n",
       "2020-01-02 11:00:00+00:00   46.92000    46.71      46.79  ...        NaN   \n",
       "2020-01-02 12:00:00+00:00   46.88000    46.63      46.86  ...        NaN   \n",
       "2020-01-02 13:00:00+00:00   46.95000    46.63      46.90  ...        NaN   \n",
       "...                              ...      ...        ...  ...        ...   \n",
       "2025-06-30 19:00:00+00:00  142.24000   141.22     141.89  ...  107760.75   \n",
       "2025-06-30 20:00:00+00:00  144.01955   141.01     141.70  ...  107528.57   \n",
       "2025-06-30 21:00:00+00:00  143.77955   141.01     141.52  ...        NaN   \n",
       "2025-06-30 22:00:00+00:00  141.75000   141.33     141.44  ...        NaN   \n",
       "2025-06-30 23:00:00+00:00  141.46000   141.22     141.39  ...        NaN   \n",
       "\n",
       "                           btc_volume  gold_open  gold_high  gold_low  \\\n",
       "timestamp                                                               \n",
       "2020-01-02 09:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2020-01-02 10:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2020-01-02 11:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2020-01-02 12:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2020-01-02 13:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "...                               ...        ...        ...       ...   \n",
       "2025-06-30 19:00:00+00:00     10943.0    3298.40    3309.47   3297.98   \n",
       "2025-06-30 20:00:00+00:00      9128.0    3308.65    3309.13   3302.22   \n",
       "2025-06-30 21:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2025-06-30 22:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "2025-06-30 23:00:00+00:00         NaN        NaN        NaN       NaN   \n",
       "\n",
       "                           gold_close  gold_volume  overall_sentiment_score  \\\n",
       "timestamp                                                                     \n",
       "2020-01-02 09:00:00+00:00         NaN          NaN                      NaN   \n",
       "2020-01-02 10:00:00+00:00         NaN          NaN                      NaN   \n",
       "2020-01-02 11:00:00+00:00         NaN          NaN                      NaN   \n",
       "2020-01-02 12:00:00+00:00         NaN          NaN                      NaN   \n",
       "2020-01-02 13:00:00+00:00         NaN          NaN                      NaN   \n",
       "...                               ...          ...                      ...   \n",
       "2025-06-30 19:00:00+00:00     3308.65      10356.0                 0.211782   \n",
       "2025-06-30 20:00:00+00:00     3302.95       4943.0                 0.358923   \n",
       "2025-06-30 21:00:00+00:00         NaN          NaN                 0.190412   \n",
       "2025-06-30 22:00:00+00:00         NaN          NaN                 0.000000   \n",
       "2025-06-30 23:00:00+00:00         NaN          NaN                 0.171347   \n",
       "\n",
       "                           nvda_sentiment_score  nvda_relevance_score  \n",
       "timestamp                                                              \n",
       "2020-01-02 09:00:00+00:00                   NaN                   NaN  \n",
       "2020-01-02 10:00:00+00:00                   NaN                   NaN  \n",
       "2020-01-02 11:00:00+00:00                   NaN                   NaN  \n",
       "2020-01-02 12:00:00+00:00                   NaN                   NaN  \n",
       "2020-01-02 13:00:00+00:00                   NaN                   NaN  \n",
       "...                                         ...                   ...  \n",
       "2025-06-30 19:00:00+00:00              0.053219              0.150592  \n",
       "2025-06-30 20:00:00+00:00              0.043446              0.043264  \n",
       "2025-06-30 21:00:00+00:00              0.122056              0.208046  \n",
       "2025-06-30 22:00:00+00:00              0.000000              0.000000  \n",
       "2025-06-30 23:00:00+00:00              0.044447              0.159569  \n",
       "\n",
       "[21925 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7049414b-e325-45e4-a4ee-a45284c9a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['data','open','high','low','close','tickvol','volume','spread']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb989a5e-ec51-44e9-8877-46c12f4e16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 14\n",
    "df['y'] = (df['nvda_open'] < df['nvda_close']).astype(int)\n",
    "df['y'] = df['y'].shift(-1)\n",
    "\n",
    "## ðŸ’¨ Momentum Indicators\n",
    "# RSI\n",
    "df['rsi_14'] = talib.RSI(df['nvda_close'], timeperiod=14)\n",
    "\n",
    "# Stochastic Oscillator\n",
    "df['stoch_k'], df['stoch_d'] = talib.STOCH(\n",
    "    df['nvda_high'], df['nvda_low'], df['nvda_close'],\n",
    "    fastk_period=14, slowk_period=3, slowd_period=3\n",
    ")\n",
    "\n",
    "# MACD\n",
    "df['macd'], df['macd_signal'], df['macd_hist'] = talib.MACD(\n",
    "    df['nvda_close'],\n",
    "    fastperiod=12, slowperiod=26, signalperiod=9\n",
    ")\n",
    "\n",
    "## ðŸ“ˆ Trend Indicators\n",
    "# We calculate the SMA to create our custom feature\n",
    "sma_20 = talib.SMA(df['nvda_close'], timeperiod=window_size)\n",
    "df['price_to_sma'] = (df['nvda_close'] - sma_20) / sma_20\n",
    "\n",
    "## ðŸŒŠ Volatility Indicators\n",
    "# ATR\n",
    "df['atr_14'] = talib.ATR(\n",
    "    df['nvda_high'], df['nvda_low'], df['nvda_close'],\n",
    "    timeperiod=14\n",
    ")\n",
    "\n",
    "# Bollinger Bands\n",
    "upper_bb, middle_bb, lower_bb = talib.BBANDS(\n",
    "    df['nvda_close'],\n",
    "    timeperiod=window_size, nbdevup=2, nbdevdn=2\n",
    ")\n",
    "# Create the \"Bollinger Band Width\" feature\n",
    "df['bb_width'] = (upper_bb - lower_bb) / middle_bb\n",
    "\n",
    "## ðŸ“Š Volume Indicators\n",
    "# On-Balance Volume (OBV)\n",
    "df['obv'] = talib.OBV(df['nvda_close'], df['nvda_volume'])\n",
    "# Create the \"OBV Slope\" feature (using a 10-period change)\n",
    "df['obv_slope'] = df['obv'].diff(periods=10)\n",
    "# df['rsi_lag_1'] = df['rsi_14'].shift(1)\n",
    "# df['rsi_lag_2'] = df['rsi_14'].shift(2)\n",
    "# df['price_to_sma_lag_1'] = df['price_to_sma'].shift(1)\n",
    "# df['bb_width_lag_1'] = df['bb_width'].shift(1)\n",
    "# df['atr_lag_1'] = df['atr_14'].shift(1)\n",
    "# df.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de03d06b-8e4d-4b85-8f4c-3c0c9c194503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_987948/3073380282.py:15: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  'gold_high', 'gold_low', 'gold_close', 'gold_volume']].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df[['amd_open', 'amd_high', 'amd_low', 'amd_close',\n",
    "       'amd_volume', 'intc_open', 'intc_high', 'intc_low', 'intc_close',\n",
    "       'intc_volume', 'spy_open', 'spy_high', 'spy_low', 'spy_close',\n",
    "       'spy_volume', 'dia_open', 'dia_high', 'dia_low', 'dia_close',\n",
    "       'dia_volume', 'iwm_open', 'iwm_high', 'iwm_low', 'iwm_close',\n",
    "       'iwm_volume','btc_open',\n",
    "       'btc_high', 'btc_low', 'btc_close', 'btc_volume', 'gold_open',\n",
    "       'gold_high', 'gold_low', 'gold_close', 'gold_volume']] = df[['amd_open', 'amd_high', 'amd_low', 'amd_close',\n",
    "       'amd_volume', 'intc_open', 'intc_high', 'intc_low', 'intc_close',\n",
    "       'intc_volume', 'spy_open', 'spy_high', 'spy_low', 'spy_close',\n",
    "       'spy_volume', 'dia_open', 'dia_high', 'dia_low', 'dia_close',\n",
    "       'dia_volume', 'iwm_open', 'iwm_high', 'iwm_low', 'iwm_close',\n",
    "       'iwm_volume','btc_open',\n",
    "       'btc_high', 'btc_low', 'btc_close', 'btc_volume', 'gold_open',\n",
    "       'gold_high', 'gold_low', 'gold_close', 'gold_volume']].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d0011c-0b1a-409d-89ac-8d5e9af81286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"2022-03-03 9:00\":][['overall_sentiment_score', 'nvda_sentiment_score',\n",
    "#        'nvda_relevance_score', 'y', 'rsi_14', 'stoch_k', 'stoch_d', 'macd',\n",
    "#        'macd_signal', 'macd_hist', 'price_to_sma', 'atr_14', 'bb_width', 'obv',\n",
    "#        'obv_slope', 'rsi_lag_1', 'rsi_lag_2', 'price_to_sma_lag_1',\n",
    "#        'bb_width_lag_1', 'atr_lag_1']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6356aee2-7c5e-41c4-8459-e89677d40b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a7f40a-5899-4dce-9df4-d4d9c37e9fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>nvda_open</th>\n",
       "      <th>nvda_high</th>\n",
       "      <th>nvda_low</th>\n",
       "      <th>nvda_close</th>\n",
       "      <th>nvda_volume</th>\n",
       "      <th>amd_open</th>\n",
       "      <th>amd_high</th>\n",
       "      <th>amd_low</th>\n",
       "      <th>amd_close</th>\n",
       "      <th>...</th>\n",
       "      <th>stoch_k</th>\n",
       "      <th>stoch_d</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>price_to_sma</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>obv</th>\n",
       "      <th>obv_slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-03 09:00:00+00:00</th>\n",
       "      <td>2022-03-03 09:00:00+00:00</td>\n",
       "      <td>24.0095</td>\n",
       "      <td>24.0374</td>\n",
       "      <td>23.9216</td>\n",
       "      <td>23.9735</td>\n",
       "      <td>46180</td>\n",
       "      <td>117.4600</td>\n",
       "      <td>117.50000</td>\n",
       "      <td>116.900</td>\n",
       "      <td>117.40</td>\n",
       "      <td>...</td>\n",
       "      <td>58.092946</td>\n",
       "      <td>58.122658</td>\n",
       "      <td>0.071580</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.231889</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>6.500109e+09</td>\n",
       "      <td>70025360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03 10:00:00+00:00</th>\n",
       "      <td>2022-03-03 10:00:00+00:00</td>\n",
       "      <td>23.9795</td>\n",
       "      <td>23.9975</td>\n",
       "      <td>23.9466</td>\n",
       "      <td>23.9596</td>\n",
       "      <td>9530</td>\n",
       "      <td>117.4000</td>\n",
       "      <td>117.49000</td>\n",
       "      <td>117.200</td>\n",
       "      <td>117.38</td>\n",
       "      <td>...</td>\n",
       "      <td>58.235596</td>\n",
       "      <td>58.160142</td>\n",
       "      <td>0.066487</td>\n",
       "      <td>0.057243</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.218961</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>6.500099e+09</td>\n",
       "      <td>26313440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03 11:00:00+00:00</th>\n",
       "      <td>2022-03-03 11:00:00+00:00</td>\n",
       "      <td>23.9825</td>\n",
       "      <td>24.0484</td>\n",
       "      <td>23.9456</td>\n",
       "      <td>23.9596</td>\n",
       "      <td>50490</td>\n",
       "      <td>117.3000</td>\n",
       "      <td>117.78000</td>\n",
       "      <td>117.300</td>\n",
       "      <td>117.30</td>\n",
       "      <td>...</td>\n",
       "      <td>56.812660</td>\n",
       "      <td>57.713734</td>\n",
       "      <td>0.061739</td>\n",
       "      <td>0.058142</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>0.210664</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>6.500099e+09</td>\n",
       "      <td>-3122080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03 12:00:00+00:00</th>\n",
       "      <td>2022-03-03 12:00:00+00:00</td>\n",
       "      <td>23.9945</td>\n",
       "      <td>24.0694</td>\n",
       "      <td>23.9596</td>\n",
       "      <td>24.0574</td>\n",
       "      <td>166470</td>\n",
       "      <td>117.5400</td>\n",
       "      <td>117.94000</td>\n",
       "      <td>117.450</td>\n",
       "      <td>117.65</td>\n",
       "      <td>...</td>\n",
       "      <td>59.804748</td>\n",
       "      <td>58.284334</td>\n",
       "      <td>0.065117</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.203460</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>6.500266e+09</td>\n",
       "      <td>-29258710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03 13:00:00+00:00</th>\n",
       "      <td>2022-03-03 13:00:00+00:00</td>\n",
       "      <td>23.9715</td>\n",
       "      <td>24.2750</td>\n",
       "      <td>23.9715</td>\n",
       "      <td>24.2680</td>\n",
       "      <td>776990</td>\n",
       "      <td>117.8001</td>\n",
       "      <td>118.26000</td>\n",
       "      <td>117.432</td>\n",
       "      <td>118.26</td>\n",
       "      <td>...</td>\n",
       "      <td>70.100361</td>\n",
       "      <td>62.239256</td>\n",
       "      <td>0.083822</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.019428</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.210605</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>6.501043e+09</td>\n",
       "      <td>-59969930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 18:00:00+00:00</th>\n",
       "      <td>2025-06-30 18:00:00+00:00</td>\n",
       "      <td>157.8111</td>\n",
       "      <td>158.0161</td>\n",
       "      <td>156.8311</td>\n",
       "      <td>157.7361</td>\n",
       "      <td>14311666</td>\n",
       "      <td>142.3450</td>\n",
       "      <td>142.43000</td>\n",
       "      <td>141.400</td>\n",
       "      <td>141.71</td>\n",
       "      <td>...</td>\n",
       "      <td>74.995658</td>\n",
       "      <td>75.831163</td>\n",
       "      <td>0.562108</td>\n",
       "      <td>0.721528</td>\n",
       "      <td>-0.159420</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>1.188289</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>1.978200e+10</td>\n",
       "      <td>-28124420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 19:00:00+00:00</th>\n",
       "      <td>2025-06-30 19:00:00+00:00</td>\n",
       "      <td>157.7411</td>\n",
       "      <td>158.6510</td>\n",
       "      <td>157.6611</td>\n",
       "      <td>157.8611</td>\n",
       "      <td>26770205</td>\n",
       "      <td>141.7200</td>\n",
       "      <td>142.24000</td>\n",
       "      <td>141.220</td>\n",
       "      <td>141.89</td>\n",
       "      <td>...</td>\n",
       "      <td>72.165016</td>\n",
       "      <td>75.129133</td>\n",
       "      <td>0.528390</td>\n",
       "      <td>0.682900</td>\n",
       "      <td>-0.154510</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>1.174118</td>\n",
       "      <td>0.014222</td>\n",
       "      <td>1.980877e+10</td>\n",
       "      <td>-1354215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 20:00:00+00:00</th>\n",
       "      <td>2025-06-30 20:00:00+00:00</td>\n",
       "      <td>157.8611</td>\n",
       "      <td>158.6600</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>72869000</td>\n",
       "      <td>141.8900</td>\n",
       "      <td>144.01955</td>\n",
       "      <td>141.010</td>\n",
       "      <td>141.70</td>\n",
       "      <td>...</td>\n",
       "      <td>69.890375</td>\n",
       "      <td>72.350350</td>\n",
       "      <td>0.489569</td>\n",
       "      <td>0.644234</td>\n",
       "      <td>-0.154664</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>1.283110</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>1.973590e+10</td>\n",
       "      <td>-74223215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 21:00:00+00:00</th>\n",
       "      <td>2025-06-30 21:00:00+00:00</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>158.6600</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>157.7811</td>\n",
       "      <td>223935</td>\n",
       "      <td>141.6500</td>\n",
       "      <td>143.77955</td>\n",
       "      <td>141.010</td>\n",
       "      <td>141.52</td>\n",
       "      <td>...</td>\n",
       "      <td>68.435802</td>\n",
       "      <td>70.163731</td>\n",
       "      <td>0.453575</td>\n",
       "      <td>0.606102</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>-0.001334</td>\n",
       "      <td>1.384316</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>1.973590e+10</td>\n",
       "      <td>-73691014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 22:00:00+00:00</th>\n",
       "      <td>2025-06-30 22:00:00+00:00</td>\n",
       "      <td>157.7611</td>\n",
       "      <td>157.7911</td>\n",
       "      <td>157.4911</td>\n",
       "      <td>157.5113</td>\n",
       "      <td>219009</td>\n",
       "      <td>141.5200</td>\n",
       "      <td>141.75000</td>\n",
       "      <td>141.330</td>\n",
       "      <td>141.44</td>\n",
       "      <td>...</td>\n",
       "      <td>64.117284</td>\n",
       "      <td>67.481154</td>\n",
       "      <td>0.398683</td>\n",
       "      <td>0.564619</td>\n",
       "      <td>-0.165935</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>1.306865</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>1.973568e+10</td>\n",
       "      <td>-71967436.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13325 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           timestamp  nvda_open  nvda_high  \\\n",
       "timestamp                                                                    \n",
       "2022-03-03 09:00:00+00:00  2022-03-03 09:00:00+00:00    24.0095    24.0374   \n",
       "2022-03-03 10:00:00+00:00  2022-03-03 10:00:00+00:00    23.9795    23.9975   \n",
       "2022-03-03 11:00:00+00:00  2022-03-03 11:00:00+00:00    23.9825    24.0484   \n",
       "2022-03-03 12:00:00+00:00  2022-03-03 12:00:00+00:00    23.9945    24.0694   \n",
       "2022-03-03 13:00:00+00:00  2022-03-03 13:00:00+00:00    23.9715    24.2750   \n",
       "...                                              ...        ...        ...   \n",
       "2025-06-30 18:00:00+00:00  2025-06-30 18:00:00+00:00   157.8111   158.0161   \n",
       "2025-06-30 19:00:00+00:00  2025-06-30 19:00:00+00:00   157.7411   158.6510   \n",
       "2025-06-30 20:00:00+00:00  2025-06-30 20:00:00+00:00   157.8611   158.6600   \n",
       "2025-06-30 21:00:00+00:00  2025-06-30 21:00:00+00:00   157.7811   158.6600   \n",
       "2025-06-30 22:00:00+00:00  2025-06-30 22:00:00+00:00   157.7611   157.7911   \n",
       "\n",
       "                           nvda_low  nvda_close  nvda_volume  amd_open  \\\n",
       "timestamp                                                                \n",
       "2022-03-03 09:00:00+00:00   23.9216     23.9735        46180  117.4600   \n",
       "2022-03-03 10:00:00+00:00   23.9466     23.9596         9530  117.4000   \n",
       "2022-03-03 11:00:00+00:00   23.9456     23.9596        50490  117.3000   \n",
       "2022-03-03 12:00:00+00:00   23.9596     24.0574       166470  117.5400   \n",
       "2022-03-03 13:00:00+00:00   23.9715     24.2680       776990  117.8001   \n",
       "...                             ...         ...          ...       ...   \n",
       "2025-06-30 18:00:00+00:00  156.8311    157.7361     14311666  142.3450   \n",
       "2025-06-30 19:00:00+00:00  157.6611    157.8611     26770205  141.7200   \n",
       "2025-06-30 20:00:00+00:00  155.9600    157.7811     72869000  141.8900   \n",
       "2025-06-30 21:00:00+00:00  155.9600    157.7811       223935  141.6500   \n",
       "2025-06-30 22:00:00+00:00  157.4911    157.5113       219009  141.5200   \n",
       "\n",
       "                            amd_high  amd_low  amd_close  ...    stoch_k  \\\n",
       "timestamp                                                 ...              \n",
       "2022-03-03 09:00:00+00:00  117.50000  116.900     117.40  ...  58.092946   \n",
       "2022-03-03 10:00:00+00:00  117.49000  117.200     117.38  ...  58.235596   \n",
       "2022-03-03 11:00:00+00:00  117.78000  117.300     117.30  ...  56.812660   \n",
       "2022-03-03 12:00:00+00:00  117.94000  117.450     117.65  ...  59.804748   \n",
       "2022-03-03 13:00:00+00:00  118.26000  117.432     118.26  ...  70.100361   \n",
       "...                              ...      ...        ...  ...        ...   \n",
       "2025-06-30 18:00:00+00:00  142.43000  141.400     141.71  ...  74.995658   \n",
       "2025-06-30 19:00:00+00:00  142.24000  141.220     141.89  ...  72.165016   \n",
       "2025-06-30 20:00:00+00:00  144.01955  141.010     141.70  ...  69.890375   \n",
       "2025-06-30 21:00:00+00:00  143.77955  141.010     141.52  ...  68.435802   \n",
       "2025-06-30 22:00:00+00:00  141.75000  141.330     141.44  ...  64.117284   \n",
       "\n",
       "                             stoch_d      macd  macd_signal  macd_hist  \\\n",
       "timestamp                                                                \n",
       "2022-03-03 09:00:00+00:00  58.122658  0.071580     0.054932   0.016648   \n",
       "2022-03-03 10:00:00+00:00  58.160142  0.066487     0.057243   0.009244   \n",
       "2022-03-03 11:00:00+00:00  57.713734  0.061739     0.058142   0.003597   \n",
       "2022-03-03 12:00:00+00:00  58.284334  0.065117     0.059537   0.005580   \n",
       "2022-03-03 13:00:00+00:00  62.239256  0.083822     0.064394   0.019428   \n",
       "...                              ...       ...          ...        ...   \n",
       "2025-06-30 18:00:00+00:00  75.831163  0.562108     0.721528  -0.159420   \n",
       "2025-06-30 19:00:00+00:00  75.129133  0.528390     0.682900  -0.154510   \n",
       "2025-06-30 20:00:00+00:00  72.350350  0.489569     0.644234  -0.154664   \n",
       "2025-06-30 21:00:00+00:00  70.163731  0.453575     0.606102  -0.152527   \n",
       "2025-06-30 22:00:00+00:00  67.481154  0.398683     0.564619  -0.165935   \n",
       "\n",
       "                           price_to_sma    atr_14  bb_width           obv  \\\n",
       "timestamp                                                                   \n",
       "2022-03-03 09:00:00+00:00      0.001353  0.231889  0.032379  6.500109e+09   \n",
       "2022-03-03 10:00:00+00:00     -0.000089  0.218961  0.029836  6.500099e+09   \n",
       "2022-03-03 11:00:00+00:00     -0.001209  0.210664  0.024157  6.500099e+09   \n",
       "2022-03-03 12:00:00+00:00      0.002022  0.203460  0.022117  6.500266e+09   \n",
       "2022-03-03 13:00:00+00:00      0.008960  0.210605  0.017972  6.501043e+09   \n",
       "...                                 ...       ...       ...           ...   \n",
       "2025-06-30 18:00:00+00:00     -0.001190  1.188289  0.014730  1.978200e+10   \n",
       "2025-06-30 19:00:00+00:00     -0.000620  1.174118  0.014222  1.980877e+10   \n",
       "2025-06-30 20:00:00+00:00     -0.001231  1.283110  0.013996  1.973590e+10   \n",
       "2025-06-30 21:00:00+00:00     -0.001334  1.384316  0.013753  1.973590e+10   \n",
       "2025-06-30 22:00:00+00:00     -0.002524  1.306865  0.013235  1.973568e+10   \n",
       "\n",
       "                            obv_slope  \n",
       "timestamp                              \n",
       "2022-03-03 09:00:00+00:00  70025360.0  \n",
       "2022-03-03 10:00:00+00:00  26313440.0  \n",
       "2022-03-03 11:00:00+00:00  -3122080.0  \n",
       "2022-03-03 12:00:00+00:00 -29258710.0  \n",
       "2022-03-03 13:00:00+00:00 -59969930.0  \n",
       "...                               ...  \n",
       "2025-06-30 18:00:00+00:00 -28124420.0  \n",
       "2025-06-30 19:00:00+00:00  -1354215.0  \n",
       "2025-06-30 20:00:00+00:00 -74223215.0  \n",
       "2025-06-30 21:00:00+00:00 -73691014.0  \n",
       "2025-06-30 22:00:00+00:00 -71967436.0  \n",
       "\n",
       "[13325 rows x 57 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b553e80f-e544-4d32-b4be-b06c51ecec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['high','low'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f448f9b7-b163-477b-aceb-b7e63e122dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y',axis=1)\n",
    "# df\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523f1bb3-716c-4ceb-93b4-aa25295c808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205d2fa-4225-4c31-8adb-81caf0d66e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa46401-d372-4018-8499-9abb7d1f4dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4792e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size = 24\n",
    "\n",
    "# # Create list of windows\n",
    "# windows = []\n",
    "# for i in range(len(X) - window_size + 1):\n",
    "#     # Take 30 consecutive rows for all columns, flatten them into 1D array\n",
    "#     window = X.iloc[i:i + window_size].values.flatten()\n",
    "#     windows.append(window)\n",
    "# cols = []\n",
    "# for col in X.columns:\n",
    "#     for j in range(window_size):\n",
    "#         cols.append(f\"{col}_{j}\")\n",
    "\n",
    "# # Make new DataFrame\n",
    "# X_new = pd.DataFrame(windows, columns=cols)\n",
    "# y_new = y[window_size - 1:].reset_index(drop=True)\n",
    "# X_new = X_new.reset_index(drop=True)\n",
    "# # print(df_windows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c241d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 13325\n",
      "Training samples: 9327\n",
      "Validation samples: 1998\n",
      "Testing samples: 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_curve,auc\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train_split = 0.7\n",
    "val_split = 0.15  # 15%\n",
    "test_split = 0.15  # 15%\n",
    "\n",
    "# Calculate split indices\n",
    "train_end = int(len(X) * train_split)\n",
    "val_end = train_end + int(len(X) * val_split)\n",
    "\n",
    "# Split the data\n",
    "X_train = X.iloc[:train_end]\n",
    "X_val = X.iloc[train_end:val_end]\n",
    "X_test = X.iloc[val_end:]\n",
    "\n",
    "y_train = y.iloc[:train_end]\n",
    "y_val = y.iloc[train_end:val_end]\n",
    "y_test = y.iloc[val_end:]\n",
    "\n",
    "# Scale data (fit only on training set)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Print sizes\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Training samples: {len(X_train_scaled)}\")\n",
    "print(f\"Validation samples: {len(X_val_scaled)}\")\n",
    "print(f\"Testing samples: {len(X_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2469e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = CustomDataset(X_train_scaled,y_train,window_size=window_size)\n",
    "valDataset = CustomDataset(X_val_scaled,y_val,window_size=window_size)\n",
    "testDataset = CustomDataset(X_test_scaled,y_test,window_size=window_size)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=trainDataset, batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "val_loader = DataLoader(dataset=valDataset, batch_size=1, shuffle=False,drop_last=True)\n",
    "test_loader = DataLoader(dataset=testDataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79bc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b3424f-4fb4-484f-9fe4-64ee5c37b599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 55, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4e55567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Successful ---\n",
      "Input tensor shape:  torch.Size([32, 55, 14]) (Batch x feature x window size)\n",
      "Output tensor shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# model = CNN_LSTM(3,50,1,1).to('cuda')\n",
    "model = CNN_LSTM_Model(55,window_size).to('cuda')\n",
    "# model = HybridGSRModel(55).to('cuda')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(temp.to('cuda'))\n",
    "print(\"\\n--- Test Successful ---\")\n",
    "print(f\"Input tensor shape:  {temp.shape} (Batch x feature x window size)\")\n",
    "print(f\"Output tensor shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b8c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0c29e54-6e37-408c-b35d-9a4b0628d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89856d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      " Train Loss: 0.6933\n",
      " Val   -> Loss: 0.6901 | Acc: 0.5395 | Precision: 0.3333 | Recall: 0.0011 | F1: 0.0022 | AUC: 0.4970\n",
      " Test  -> Loss: 0.6914 | Acc: 0.5325 | Precision: 0.4762 | Recall: 0.2200 | F1: 0.3010 | AUC: 0.4961\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125842/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]\n",
      " Train Loss: 0.6897\n",
      " Val   -> Loss: 0.6901 | Acc: 0.5395 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000 | AUC: 0.5122\n",
      " Test  -> Loss: 0.6901 | Acc: 0.5425 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000 | AUC: 0.5119\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [3/20]\n",
      " Train Loss: 0.6891\n",
      " Val   -> Loss: 0.7006 | Acc: 0.5285 | Precision: 0.4588 | Recall: 0.1402 | F1: 0.2148 | AUC: 0.5090\n",
      " Test  -> Loss: 0.7067 | Acc: 0.5164 | Precision: 0.4366 | Recall: 0.1969 | F1: 0.2714 | AUC: 0.4864\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [4/20]\n",
      " Train Loss: 0.6873\n",
      " Val   -> Loss: 0.6946 | Acc: 0.5370 | Precision: 0.4483 | Recall: 0.0285 | F1: 0.0536 | AUC: 0.4906\n",
      " Test  -> Loss: 0.6943 | Acc: 0.5335 | Precision: 0.4511 | Recall: 0.0913 | F1: 0.1519 | AUC: 0.5184\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125842/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]\n",
      " Train Loss: 0.6847\n",
      " Val   -> Loss: 0.6949 | Acc: 0.5385 | Precision: 0.4483 | Recall: 0.0142 | F1: 0.0276 | AUC: 0.4944\n",
      " Test  -> Loss: 0.6899 | Acc: 0.5425 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000 | AUC: 0.5569\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [6/20]\n",
      " Train Loss: 0.6841\n",
      " Val   -> Loss: 0.6911 | Acc: 0.5401 | Precision: 0.5000 | Recall: 0.0088 | F1: 0.0172 | AUC: 0.5133\n",
      " Test  -> Loss: 0.6917 | Acc: 0.5425 | Precision: 0.5000 | Recall: 0.0011 | F1: 0.0022 | AUC: 0.4983\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_probs = []  # for AUC\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(float)\n",
    "            val_probs.extend(probs)\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_precision = precision_score(val_labels, val_preds)\n",
    "    val_recall = recall_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "    val_acc = (np.array(val_preds) == np.array(val_labels)).mean()\n",
    "    val_auc = roc_auc_score(val_labels, val_probs)\n",
    "\n",
    "    # --- Test ---\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    test_probs = []  # for AUC\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(float)\n",
    "            test_probs.extend(probs)\n",
    "            test_preds.extend(preds)\n",
    "            test_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_precision = precision_score(test_labels, test_preds)\n",
    "    test_recall = recall_score(test_labels, test_preds)\n",
    "    test_f1 = f1_score(test_labels, test_preds)\n",
    "    test_acc = (np.array(test_preds) == np.array(test_labels)).mean()\n",
    "    test_auc = roc_auc_score(test_labels, test_probs)\n",
    "\n",
    "    # --- Print results ---\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\" Train Loss: {train_loss:.4f}\")\n",
    "    print(f\" Val   -> Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | \"\n",
    "          f\"F1: {val_f1:.4f} | AUC: {val_auc:.4f}\")\n",
    "    print(f\" Test  -> Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | \"\n",
    "          f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | \"\n",
    "          f\"F1: {test_f1:.4f} | AUC: {test_auc:.4f}\")\n",
    "    print(\"-\" * 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5c06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0a2a8-3409-4bbd-9a7e-33bf6a0a6790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a54d26-7e9a-4617-ace1-9065555f86ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea21cd7-3b88-4bb4-aec1-fb873e1f75d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88c495-448d-4bc5-941b-a3d66971bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819336e-d557-4490-a5e7-eb2848870820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306d803-1f01-4f50-88bf-a23ce5352d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d24e4-3db0-44ed-95a4-36eaa0b6efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048e05d-2537-409b-b070-4f9dbfb7cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f79c3-0365-40fd-8468-b85abbfa8e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
